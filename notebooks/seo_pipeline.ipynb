{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b43c5f0b",
   "metadata": {},
   "source": [
    "# SEO Content Quality & Duplicate Detector\n",
    "\n",
    "This notebook implements a complete machine learning pipeline for analyzing web content quality and detecting duplicates. The system processes HTML content, extracts features, and builds a classification model to score content quality.\n",
    "\n",
    "## Project Overview\n",
    "- **Parse HTML content** from provided dataset\n",
    "- **Extract text features** including readability scores and keywords\n",
    "- **Detect duplicate content** using similarity algorithms\n",
    "- **Build quality classification model** with performance evaluation\n",
    "- **Provide real-time analysis** for new URLs\n",
    "\n",
    "## Dataset\n",
    "We're using the primary dataset with pre-scraped HTML content (data.csv) containing ~70 URLs with their HTML content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4266c326",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7630e847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "All libraries imported successfully!\n",
      "Python environment ready for SEO content analysis.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# HTML parsing\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Text processing\n",
    "import textstat\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(\"Python environment ready for SEO content analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff3f95ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully!\n",
      "Shape: (81, 2)\n",
      "Columns: ['url', 'html_content']\n",
      "First few URLs:\n",
      "  1. https://www.cm-alliance.com/cybersecurity-blog\n",
      "  2. https://www.varonis.com/blog/cybersecurity-tips\n",
      "  3. https://www.cisecurity.org/insights/blog/11-cyber-defense-tips-to-stay-secure-at-work-and-home\n",
      "\n",
      "Missing values:\n",
      "url              0\n",
      "html_content    12\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('../data.csv')\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"First few URLs:\")\n",
    "for i, url in enumerate(df['url'].head(3)):\n",
    "    print(f\"  {i+1}. {url}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9264fb5e",
   "metadata": {},
   "source": [
    "## 2. HTML Content Parsing and Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8a140d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML parsing function created successfully!\n"
     ]
    }
   ],
   "source": [
    "def extract_content_from_html(html_content):\n",
    "    \"\"\"\n",
    "    Extract title, body text, and word count from HTML content.\n",
    "    Returns a dictionary with extracted information.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse HTML with BeautifulSoup\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        \n",
    "        # Extract title\n",
    "        title_tag = soup.find('title')\n",
    "        title = title_tag.get_text().strip() if title_tag else \"No Title\"\n",
    "        \n",
    "        # Remove script and style elements\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.decompose()\n",
    "        \n",
    "        # Extract text from main content areas\n",
    "        body_text = \"\"\n",
    "        \n",
    "        # Try to find main content in common tags\n",
    "        content_tags = soup.find_all(['p', 'article', 'main', 'div', 'section'])\n",
    "        for tag in content_tags:\n",
    "            text = tag.get_text()\n",
    "            if len(text.strip()) > 20:  # Only add meaningful text blocks\n",
    "                body_text += text + \" \"\n",
    "        \n",
    "        # If no content found, use body text\n",
    "        if not body_text.strip():\n",
    "            body = soup.find('body')\n",
    "            body_text = body.get_text() if body else soup.get_text()\n",
    "        \n",
    "        # Clean the text\n",
    "        body_text = re.sub(r'\\s+', ' ', body_text).strip()\n",
    "        \n",
    "        # Calculate word count\n",
    "        word_count = len(body_text.split()) if body_text else 0\n",
    "        \n",
    "        return {\n",
    "            'title': title,\n",
    "            'body_text': body_text,\n",
    "            'word_count': word_count\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing HTML: {str(e)}\")\n",
    "        return {\n",
    "            'title': \"Parse Error\",\n",
    "            'body_text': \"\",\n",
    "            'word_count': 0\n",
    "        }\n",
    "\n",
    "print(\"HTML parsing function created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6462af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HTML content...\n",
      "Error parsing HTML: Incoming markup is of an invalid type: nan. Markup must be a string, a bytestring, or an open filehandle.\n",
      "Processed 10 pages...\n",
      "Error parsing HTML: Incoming markup is of an invalid type: nan. Markup must be a string, a bytestring, or an open filehandle.\n",
      "Error parsing HTML: Incoming markup is of an invalid type: nan. Markup must be a string, a bytestring, or an open filehandle.\n",
      "Processed 20 pages...\n",
      "Error parsing HTML: Incoming markup is of an invalid type: nan. Markup must be a string, a bytestring, or an open filehandle.\n",
      "Error parsing HTML: Incoming markup is of an invalid type: nan. Markup must be a string, a bytestring, or an open filehandle.\n",
      "Processed 30 pages...\n",
      "Processed 40 pages...\n",
      "Error parsing HTML: Incoming markup is of an invalid type: nan. Markup must be a string, a bytestring, or an open filehandle.\n",
      "Error parsing HTML: Incoming markup is of an invalid type: nan. Markup must be a string, a bytestring, or an open filehandle.\n",
      "Processed 50 pages...\n",
      "Error parsing HTML: Incoming markup is of an invalid type: nan. Markup must be a string, a bytestring, or an open filehandle.\n",
      "Error parsing HTML: Incoming markup is of an invalid type: nan. Markup must be a string, a bytestring, or an open filehandle.\n",
      "Processed 60 pages...\n",
      "Processed 70 pages...\n",
      "Error parsing HTML: Incoming markup is of an invalid type: nan. Markup must be a string, a bytestring, or an open filehandle.\n",
      "Error parsing HTML: Incoming markup is of an invalid type: nan. Markup must be a string, a bytestring, or an open filehandle.\n",
      "Error parsing HTML: Incoming markup is of an invalid type: nan. Markup must be a string, a bytestring, or an open filehandle.\n",
      "Processed 80 pages...\n",
      "\n",
      "Extraction completed!\n",
      "Successfully processed 81 pages\n",
      "Average word count: 29586.4\n",
      "\n",
      "Sample extracted content:\n",
      "                                                 url  \\\n",
      "0     https://www.cm-alliance.com/cybersecurity-blog   \n",
      "1    https://www.varonis.com/blog/cybersecurity-tips   \n",
      "2  https://www.cisecurity.org/insights/blog/11-cy...   \n",
      "\n",
      "                                               title  word_count  \n",
      "0                                Cyber Security Blog       47442  \n",
      "1  Top 10 Cybersecurity Awareness Tips: How to St...       20363  \n",
      "2  11 Cyber Defense Tips to Stay Secure at Work a...       16000  \n"
     ]
    }
   ],
   "source": [
    "# Process all HTML content and extract information\n",
    "print(\"Processing HTML content...\")\n",
    "extracted_data = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    url = row['url']\n",
    "    html_content = row['html_content']\n",
    "    \n",
    "    # Extract content from HTML\n",
    "    content_info = extract_content_from_html(html_content)\n",
    "    \n",
    "    # Create record\n",
    "    record = {\n",
    "        'url': url,\n",
    "        'title': content_info['title'],\n",
    "        'body_text': content_info['body_text'],\n",
    "        'word_count': content_info['word_count']\n",
    "    }\n",
    "    \n",
    "    extracted_data.append(record)\n",
    "    \n",
    "    if (idx + 1) % 10 == 0:\n",
    "        print(f\"Processed {idx + 1} pages...\")\n",
    "\n",
    "# Create DataFrame with extracted content\n",
    "content_df = pd.DataFrame(extracted_data)\n",
    "\n",
    "print(f\"\\nExtraction completed!\")\n",
    "print(f\"Successfully processed {len(content_df)} pages\")\n",
    "print(f\"Average word count: {content_df['word_count'].mean():.1f}\")\n",
    "\n",
    "# Show sample of extracted content\n",
    "print(f\"\\nSample extracted content:\")\n",
    "print(content_df[['url', 'title', 'word_count']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efafeaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to '../data/extracted_content.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save extracted content to CSV (without HTML content to reduce file size)\n",
    "content_df.to_csv('../data/extracted_content.csv', index=False)\n",
    "print(\"Extracted content saved to '../data/extracted_content.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87ca8ce",
   "metadata": {},
   "source": [
    "## 3. Text Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab88ccf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction functions created successfully!\n"
     ]
    }
   ],
   "source": [
    "def extract_features(text):\n",
    "    \"\"\"\n",
    "    Extract comprehensive features from text content.\n",
    "    Returns dictionary with readability, keywords, and other metrics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not text or len(text.strip()) == 0:\n",
    "            return {\n",
    "                'sentence_count': 0,\n",
    "                'flesch_reading_ease': 0,\n",
    "                'top_keywords': '',\n",
    "                'avg_word_length': 0\n",
    "            }\n",
    "        \n",
    "        # Clean text\n",
    "        clean_text = re.sub(r'\\s+', ' ', text.lower().strip())\n",
    "        \n",
    "        # Calculate sentence count\n",
    "        sentences = re.split(r'[.!?]+', text)\n",
    "        sentence_count = len([s for s in sentences if s.strip()])\n",
    "        \n",
    "        # Calculate Flesch Reading Ease score\n",
    "        flesch_score = textstat.flesch_reading_ease(text)\n",
    "        \n",
    "        # Calculate average word length\n",
    "        words = clean_text.split()\n",
    "        avg_word_length = sum(len(word) for word in words) / len(words) if words else 0\n",
    "        \n",
    "        return {\n",
    "            'sentence_count': sentence_count,\n",
    "            'flesch_reading_ease': flesch_score,\n",
    "            'avg_word_length': avg_word_length\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features: {str(e)}\")\n",
    "        return {\n",
    "            'sentence_count': 0,\n",
    "            'flesch_reading_ease': 0,\n",
    "            'avg_word_length': 0\n",
    "        }\n",
    "\n",
    "def extract_keywords_tfidf(texts, n_keywords=5):\n",
    "    \"\"\"\n",
    "    Extract top keywords using TF-IDF vectorization.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Remove empty texts\n",
    "        valid_texts = [text for text in texts if text and len(text.strip()) > 10]\n",
    "        \n",
    "        if len(valid_texts) < 2:\n",
    "            return [''] * len(texts)\n",
    "        \n",
    "        # Initialize TF-IDF vectorizer\n",
    "        tfidf = TfidfVectorizer(\n",
    "            max_features=1000,\n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=2,\n",
    "            max_df=0.8\n",
    "        )\n",
    "        \n",
    "        # Fit TF-IDF on valid texts\n",
    "        tfidf_matrix = tfidf.fit_transform(valid_texts)\n",
    "        feature_names = tfidf.get_feature_names_out()\n",
    "        \n",
    "        # Extract keywords for each text\n",
    "        keywords_list = []\n",
    "        valid_idx = 0\n",
    "        \n",
    "        for text in texts:\n",
    "            if text and len(text.strip()) > 10:\n",
    "                # Get TF-IDF scores for this document\n",
    "                doc_tfidf = tfidf_matrix[valid_idx].toarray()[0]\n",
    "                \n",
    "                # Get top keywords\n",
    "                top_indices = doc_tfidf.argsort()[-n_keywords:][::-1]\n",
    "                top_keywords = [feature_names[i] for i in top_indices if doc_tfidf[i] > 0]\n",
    "                \n",
    "                keywords_list.append('|'.join(top_keywords[:n_keywords]))\n",
    "                valid_idx += 1\n",
    "            else:\n",
    "                keywords_list.append('')\n",
    "        \n",
    "        return keywords_list\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting keywords: {str(e)}\")\n",
    "        return [''] * len(texts)\n",
    "\n",
    "print(\"Feature extraction functions created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7207ec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from content...\n",
      "Extracting keywords using TF-IDF...\n",
      "Feature extraction completed!\n",
      "Features extracted for 81 pages\n",
      "\n",
      "Feature summary:\n",
      "          word_count  sentence_count  flesch_reading_ease\n",
      "count      81.000000       81.000000            81.000000\n",
      "mean    29586.407407     2086.419753            24.942706\n",
      "std     39523.204690     4180.742589            24.734314\n",
      "min         0.000000        0.000000           -29.331778\n",
      "25%      2656.000000      149.000000             3.650417\n",
      "50%     19956.000000     1094.000000            25.683542\n",
      "75%     44108.000000     2340.000000            39.067610\n",
      "max    276714.000000    32868.000000           102.522048\n"
     ]
    }
   ],
   "source": [
    "# Extract features for all content\n",
    "print(\"Extracting features from content...\")\n",
    "\n",
    "features_data = []\n",
    "\n",
    "# Extract basic features for each page\n",
    "for idx, row in content_df.iterrows():\n",
    "    text = row['body_text']\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_features(text)\n",
    "    \n",
    "    # Create feature record\n",
    "    feature_record = {\n",
    "        'url': row['url'],\n",
    "        'word_count': row['word_count'],\n",
    "        'sentence_count': features['sentence_count'],\n",
    "        'flesch_reading_ease': features['flesch_reading_ease'],\n",
    "        'avg_word_length': features['avg_word_length']\n",
    "    }\n",
    "    \n",
    "    features_data.append(feature_record)\n",
    "\n",
    "# Extract keywords using TF-IDF\n",
    "print(\"Extracting keywords using TF-IDF...\")\n",
    "keywords_list = extract_keywords_tfidf(content_df['body_text'].tolist())\n",
    "\n",
    "# Add keywords to features\n",
    "for i, keywords in enumerate(keywords_list):\n",
    "    features_data[i]['top_keywords'] = keywords\n",
    "\n",
    "# Create features DataFrame\n",
    "features_df = pd.DataFrame(features_data)\n",
    "\n",
    "print(f\"Feature extraction completed!\")\n",
    "print(f\"Features extracted for {len(features_df)} pages\")\n",
    "print(f\"\\nFeature summary:\")\n",
    "print(features_df[['word_count', 'sentence_count', 'flesch_reading_ease']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0d5b476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings using Sentence Transformers...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7c0b20b3254d55a64e3dc08d2075f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated successfully!\n",
      "Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings using Sentence Transformers\n",
    "print(\"Generating embeddings using Sentence Transformers...\")\n",
    "\n",
    "# Initialize the model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Prepare texts for embedding (use title + body text for better representation)\n",
    "embedding_texts = []\n",
    "for idx, row in content_df.iterrows():\n",
    "    # Combine title and body text, limit length for efficiency\n",
    "    combined_text = f\"{row['title']} {row['body_text']}\"\n",
    "    # Limit text length to 512 characters for efficiency\n",
    "    embedding_texts.append(combined_text[:512])\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(embedding_texts, show_progress_bar=True)\n",
    "\n",
    "# Add embeddings to features DataFrame\n",
    "features_df['embedding'] = [embedding.tolist() for embedding in embeddings]\n",
    "\n",
    "print(f\"Embeddings generated successfully!\")\n",
    "print(f\"Embedding dimension: {embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5cd7335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to '../data/features.csv'\n",
      "\n",
      "Sample features:\n",
      "\n",
      "URL: https://www.cm-alliance.com/cybersecurity-blog\n",
      "Word Count: 47442\n",
      "Readability: 30.1\n",
      "Keywords: cyber|cybersecurity|september 2025|incident|septem...\n",
      "\n",
      "URL: https://www.varonis.com/blog/cybersecurity-tips\n",
      "Word Count: 20363\n",
      "Readability: 30.8\n",
      "Keywords: data|security|cloud|risk|access...\n",
      "\n",
      "URL: https://www.cisecurity.org/insights/blog/11-cyber-defense-tips-to-stay-secure-at-work-and-home\n",
      "Word Count: 16000\n",
      "Readability: 21.9\n",
      "Keywords: cybersecurity|password|secure|security|cyber...\n"
     ]
    }
   ],
   "source": [
    "# Save features to CSV\n",
    "features_df.to_csv('../data/features.csv', index=False)\n",
    "print(\"Features saved to '../data/features.csv'\")\n",
    "\n",
    "# Show sample features\n",
    "print(f\"\\nSample features:\")\n",
    "sample_features = features_df[['url', 'word_count', 'flesch_reading_ease', 'top_keywords']].head(3)\n",
    "for idx, row in sample_features.iterrows():\n",
    "    print(f\"\\nURL: {row['url']}\")\n",
    "    print(f\"Word Count: {row['word_count']}\")\n",
    "    print(f\"Readability: {row['flesch_reading_ease']:.1f}\")\n",
    "    print(f\"Keywords: {row['top_keywords'][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963d8ebb",
   "metadata": {},
   "source": [
    "## 4. Duplicate Content Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13420f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity for duplicate detection...\n",
      "Similarity matrix computed: (81, 81)\n",
      "Using similarity threshold: 0.8\n",
      "Found 78 duplicate pairs above threshold 0.8\n"
     ]
    }
   ],
   "source": [
    "# Compute cosine similarity matrix\n",
    "print(\"Computing cosine similarity for duplicate detection...\")\n",
    "\n",
    "# Convert embeddings to numpy array\n",
    "embeddings_array = np.array([np.array(emb) for emb in features_df['embedding']])\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(embeddings_array)\n",
    "\n",
    "# Set similarity threshold for duplicates\n",
    "SIMILARITY_THRESHOLD = 0.80\n",
    "\n",
    "print(f\"Similarity matrix computed: {similarity_matrix.shape}\")\n",
    "print(f\"Using similarity threshold: {SIMILARITY_THRESHOLD}\")\n",
    "\n",
    "# Find duplicate pairs\n",
    "duplicate_pairs = []\n",
    "n_pages = len(features_df)\n",
    "\n",
    "for i in range(n_pages):\n",
    "    for j in range(i + 1, n_pages):\n",
    "        similarity = similarity_matrix[i][j]\n",
    "        if similarity > SIMILARITY_THRESHOLD:\n",
    "            duplicate_pairs.append({\n",
    "                'url1': features_df.iloc[i]['url'],\n",
    "                'url2': features_df.iloc[j]['url'],\n",
    "                'similarity': round(similarity, 3)\n",
    "            })\n",
    "\n",
    "print(f\"Found {len(duplicate_pairs)} duplicate pairs above threshold {SIMILARITY_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6520eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thin content detection (word count < 500):\n",
      "Thin content pages: 12 (14.8%)\n",
      "Duplicate pairs saved to '../data/duplicates.csv'\n",
      "\n",
      "Sample duplicate pairs:\n",
      "  1. Similarity: 1.0\n",
      "     URL1: https://www.qnbtrust.bank/Resources/Learning-Center/Blog/7-c...\n",
      "     URL2: https://www.connectwise.com/blog/phishing-prevention-tips...\n",
      "  2. Similarity: 1.0\n",
      "     URL1: https://www.qnbtrust.bank/Resources/Learning-Center/Blog/7-c...\n",
      "     URL2: https://www.hpe.com/us/en/what-is/sd-wan.html...\n",
      "  3. Similarity: 1.0\n",
      "     URL1: https://www.qnbtrust.bank/Resources/Learning-Center/Blog/7-c...\n",
      "     URL2: https://support.microsoft.com/en-us/windows/how-to-use-remot...\n",
      "\n",
      "=== DUPLICATE DETECTION SUMMARY ===\n",
      "Total pages analyzed: 81\n",
      "Duplicate pairs found: 78\n",
      "Thin content pages: 12 (14.8%)\n",
      "Average similarity score: 0.192\n"
     ]
    }
   ],
   "source": [
    "# Detect thin content (word count < 500)\n",
    "THIN_CONTENT_THRESHOLD = 500\n",
    "\n",
    "features_df['is_thin'] = features_df['word_count'] < THIN_CONTENT_THRESHOLD\n",
    "thin_content_count = features_df['is_thin'].sum()\n",
    "\n",
    "print(f\"Thin content detection (word count < {THIN_CONTENT_THRESHOLD}):\")\n",
    "print(f\"Thin content pages: {thin_content_count} ({thin_content_count/len(features_df)*100:.1f}%)\")\n",
    "\n",
    "# Save duplicate pairs to CSV\n",
    "if duplicate_pairs:\n",
    "    duplicates_df = pd.DataFrame(duplicate_pairs)\n",
    "    duplicates_df.to_csv('../data/duplicates.csv', index=False)\n",
    "    print(f\"Duplicate pairs saved to '../data/duplicates.csv'\")\n",
    "    \n",
    "    # Show sample duplicates\n",
    "    print(f\"\\nSample duplicate pairs:\")\n",
    "    for idx, pair in enumerate(duplicate_pairs[:3]):\n",
    "        print(f\"  {idx+1}. Similarity: {pair['similarity']}\")\n",
    "        print(f\"     URL1: {pair['url1'][:60]}...\")\n",
    "        print(f\"     URL2: {pair['url2'][:60]}...\")\n",
    "else:\n",
    "    # Create empty duplicates file\n",
    "    pd.DataFrame(columns=['url1', 'url2', 'similarity']).to_csv('../data/duplicates.csv', index=False)\n",
    "    print(\"No duplicates found above threshold. Empty file saved.\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n=== DUPLICATE DETECTION SUMMARY ===\")\n",
    "print(f\"Total pages analyzed: {len(features_df)}\")\n",
    "print(f\"Duplicate pairs found: {len(duplicate_pairs)}\")\n",
    "print(f\"Thin content pages: {thin_content_count} ({thin_content_count/len(features_df)*100:.1f}%)\")\n",
    "print(f\"Average similarity score: {similarity_matrix[np.triu_indices_from(similarity_matrix, k=1)].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fe2651",
   "metadata": {},
   "source": [
    "## 5. Content Quality Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "652a9508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating quality labels...\n",
      "Quality label distribution:\n",
      "  Low: 45 (55.6%)\n",
      "  Medium: 31 (38.3%)\n",
      "  High: 5 (6.2%)\n",
      "\n",
      "Sample labeled records:\n",
      "  Medium: 47442 words, 30.1 readability\n",
      "  Medium: 20363 words, 30.8 readability\n",
      "  Low: 16000 words, 21.9 readability\n",
      "  Low: 13714 words, -1.6 readability\n",
      "  Low: 0 words, 0.0 readability\n"
     ]
    }
   ],
   "source": [
    "# Create synthetic quality labels based on clear criteria\n",
    "def create_quality_labels(df):\n",
    "    \"\"\"\n",
    "    Create quality labels based on word count and readability scores.\n",
    "    \n",
    "    Labels:\n",
    "    - High: word_count > 1500 AND 50 <= readability <= 70\n",
    "    - Low: word_count < 500 OR readability < 30\n",
    "    - Medium: all other cases\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        word_count = row['word_count']\n",
    "        readability = row['flesch_reading_ease']\n",
    "        \n",
    "        if word_count > 1500 and 50 <= readability <= 70:\n",
    "            labels.append('High')\n",
    "        elif word_count < 500 or readability < 30:\n",
    "            labels.append('Low')\n",
    "        else:\n",
    "            labels.append('Medium')\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Create quality labels\n",
    "print(\"Creating quality labels...\")\n",
    "features_df['quality_label'] = create_quality_labels(features_df)\n",
    "\n",
    "# Show label distribution\n",
    "label_counts = features_df['quality_label'].value_counts()\n",
    "print(f\"Quality label distribution:\")\n",
    "for label, count in label_counts.items():\n",
    "    percentage = count / len(features_df) * 100\n",
    "    print(f\"  {label}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Show sample records with labels\n",
    "print(f\"\\nSample labeled records:\")\n",
    "sample_labeled = features_df[['url', 'word_count', 'flesch_reading_ease', 'quality_label']].head(5)\n",
    "for idx, row in sample_labeled.iterrows():\n",
    "    print(f\"  {row['quality_label']}: {row['word_count']} words, {row['flesch_reading_ease']:.1f} readability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26a82ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing machine learning features...\n",
      "Feature columns: ['word_count', 'sentence_count', 'flesch_reading_ease', 'avg_word_length']\n",
      "Feature matrix shape: (81, 4)\n",
      "Training set: 56 samples\n",
      "Test set: 25 samples\n",
      "\n",
      "Training Random Forest classifier...\n",
      "Model accuracy: 0.960\n",
      "Baseline accuracy: 0.120\n"
     ]
    }
   ],
   "source": [
    "# Prepare features for machine learning\n",
    "feature_columns = ['word_count', 'sentence_count', 'flesch_reading_ease', 'avg_word_length']\n",
    "X = features_df[feature_columns]\n",
    "y = features_df['quality_label']\n",
    "\n",
    "print(f\"Preparing machine learning features...\")\n",
    "print(f\"Feature columns: {feature_columns}\")\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "\n",
    "# Split data into training and testing sets (70/30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Train Random Forest classifier\n",
    "print(f\"\\nTraining Random Forest classifier...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    max_depth=10\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Create baseline model (word count only)\n",
    "def baseline_classifier(word_counts):\n",
    "    \"\"\"Simple baseline that classifies based on word count only.\"\"\"\n",
    "    labels = []\n",
    "    for wc in word_counts:\n",
    "        if wc < 500:\n",
    "            labels.append('Low')\n",
    "        elif wc > 1500:\n",
    "            labels.append('High')\n",
    "        else:\n",
    "            labels.append('Medium')\n",
    "    return labels\n",
    "\n",
    "baseline_pred = baseline_classifier(X_test['word_count'])\n",
    "baseline_accuracy = accuracy_score(y_test, baseline_pred)\n",
    "print(f\"Baseline accuracy: {baseline_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cba4893d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL PERFORMANCE EVALUATION ===\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.50      1.00      0.67         1\n",
      "         Low       1.00      1.00      1.00        14\n",
      "      Medium       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.96        25\n",
      "   macro avg       0.83      0.97      0.87        25\n",
      "weighted avg       0.98      0.96      0.97        25\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "        High  Low  Medium\n",
      "High       1    0       0\n",
      "Low        0   14       0\n",
      "Medium     1    0       9\n",
      "\n",
      "Top Features (by importance):\n",
      "  3. flesch_reading_ease: 0.635\n",
      "  2. sentence_count: 0.158\n",
      "  4. avg_word_length: 0.129\n",
      "  1. word_count: 0.077\n",
      "\n",
      "Model saved to '../models/quality_model.pkl'\n",
      "\n",
      "=== MODEL SUMMARY ===\n",
      "Random Forest Accuracy: 0.960\n",
      "Baseline Accuracy: 0.120\n",
      "Improvement: 0.840\n",
      "Total training samples: 56\n",
      "Total test samples: 25\n"
     ]
    }
   ],
   "source": [
    "# Detailed model evaluation\n",
    "print(\"=== MODEL PERFORMANCE EVALUATION ===\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "labels = sorted(y.unique())\n",
    "\n",
    "# Create a simple confusion matrix display\n",
    "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "print(cm_df)\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop Features (by importance):\")\n",
    "for idx, row in feature_importance.iterrows():\n",
    "    print(f\"  {idx+1}. {row['feature']}: {row['importance']:.3f}\")\n",
    "\n",
    "# Save the trained model\n",
    "with open('../models/quality_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "\n",
    "print(f\"\\nModel saved to '../models/quality_model.pkl'\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n=== MODEL SUMMARY ===\")\n",
    "print(f\"Random Forest Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Baseline Accuracy: {baseline_accuracy:.3f}\")\n",
    "print(f\"Improvement: {(accuracy - baseline_accuracy):.3f}\")\n",
    "print(f\"Total training samples: {len(X_train)}\")\n",
    "print(f\"Total test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709915b3",
   "metadata": {},
   "source": [
    "## 6. Real-Time URL Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a0fa5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real-time URL analysis function created successfully!\n",
      "Usage: result = analyze_url('https://example.com')\n"
     ]
    }
   ],
   "source": [
    "def analyze_url(url, timeout=10):\n",
    "    \"\"\"\n",
    "    Analyze a URL for content quality and duplicate detection.\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL to analyze\n",
    "        timeout (int): Request timeout in seconds\n",
    "    \n",
    "    Returns:\n",
    "        dict: Analysis results including quality score and similar content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Analyzing URL: {url}\")\n",
    "        \n",
    "        # Scrape the webpage\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers, timeout=timeout)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Extract content\n",
    "        content_info = extract_content_from_html(response.text)\n",
    "        \n",
    "        # Extract features\n",
    "        features = extract_features(content_info['body_text'])\n",
    "        \n",
    "        # Prepare feature vector for prediction\n",
    "        feature_vector = np.array([[\n",
    "            content_info['word_count'],\n",
    "            features['sentence_count'],\n",
    "            features['flesch_reading_ease'],\n",
    "            features['avg_word_length']\n",
    "        ]])\n",
    "        \n",
    "        # Predict quality\n",
    "        quality_prediction = rf_model.predict(feature_vector)[0]\n",
    "        quality_proba = rf_model.predict_proba(feature_vector)[0]\n",
    "        \n",
    "        # Generate embedding for similarity check\n",
    "        combined_text = f\"{content_info['title']} {content_info['body_text']}\"[:512]\n",
    "        new_embedding = model.encode([combined_text])[0]\n",
    "        \n",
    "        # Check similarity with existing content\n",
    "        similarities = cosine_similarity([new_embedding], embeddings_array)[0]\n",
    "        \n",
    "        # Find similar content above threshold\n",
    "        similar_content = []\n",
    "        for i, sim_score in enumerate(similarities):\n",
    "            if sim_score > 0.75:  # Slightly lower threshold for analysis\n",
    "                similar_content.append({\n",
    "                    'url': features_df.iloc[i]['url'],\n",
    "                    'similarity': round(float(sim_score), 3)\n",
    "                })\n",
    "        \n",
    "        # Sort by similarity\n",
    "        similar_content = sorted(similar_content, key=lambda x: x['similarity'], reverse=True)[:5]\n",
    "        \n",
    "        # Create result\n",
    "        result = {\n",
    "            'url': url,\n",
    "            'title': content_info['title'],\n",
    "            'word_count': content_info['word_count'],\n",
    "            'sentence_count': features['sentence_count'],\n",
    "            'readability': round(features['flesch_reading_ease'], 2),\n",
    "            'quality_label': quality_prediction,\n",
    "            'quality_confidence': {\n",
    "                'High': round(quality_proba[0], 3),\n",
    "                'Low': round(quality_proba[1], 3),\n",
    "                'Medium': round(quality_proba[2], 3)\n",
    "            },\n",
    "            'is_thin': content_info['word_count'] < THIN_CONTENT_THRESHOLD,\n",
    "            'similar_to': similar_content[:3]  # Top 3 similar\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\n",
    "            'url': url,\n",
    "            'error': f'Failed to fetch URL: {str(e)}',\n",
    "            'quality_label': 'Unknown'\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'url': url,\n",
    "            'error': f'Analysis failed: {str(e)}',\n",
    "            'quality_label': 'Unknown'\n",
    "        }\n",
    "\n",
    "print(\"Real-time URL analysis function created successfully!\")\n",
    "print(\"Usage: result = analyze_url('https://example.com')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "082d30d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing analyze_url function with: https://example.com\n",
      "==================================================\n",
      "Analyzing URL: https://example.com\n",
      "{\n",
      "  \"url\": \"https://example.com\",\n",
      "  \"title\": \"Example Domain\",\n",
      "  \"word_count\": 33,\n",
      "  \"sentence_count\": 5,\n",
      "  \"readability\": 29.26,\n",
      "  \"quality_label\": \"Low\",\n",
      "  \"quality_confidence\": {\n",
      "    \"High\": 0.0,\n",
      "    \"Low\": 0.71,\n",
      "    \"Medium\": 0.29\n",
      "  },\n",
      "  \"is_thin\": true,\n",
      "  \"similar_to\": []\n",
      "}\n",
      "\n",
      "==================================================\n",
      "Real-time analysis function is ready!\n",
      "You can now analyze any URL using: analyze_url('your-url-here')\n"
     ]
    }
   ],
   "source": [
    "# Test the analyze_url function with a sample URL\n",
    "test_url = \"https://example.com\"\n",
    "\n",
    "print(f\"Testing analyze_url function with: {test_url}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Analyze the test URL\n",
    "result = analyze_url(test_url)\n",
    "\n",
    "# Display results in a formatted way\n",
    "print(json.dumps(result, indent=2))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Real-time analysis function is ready!\")\n",
    "print(\"You can now analyze any URL using: analyze_url('your-url-here')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea25b7",
   "metadata": {},
   "source": [
    "## 7. Results Export and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15ec113a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL DATA EXPORT SUMMARY ===\n",
      "Data files created:\n",
      "    ../data/extracted_content.csv - Parsed HTML content\n",
      "    ../data/features.csv - Extracted features with embeddings\n",
      "    ../data/duplicates.csv - Duplicate content pairs\n",
      "    ../models/quality_model.pkl - Trained classification model\n",
      "\n",
      " Processing Statistics:\n",
      "   Total pages processed: 81\n",
      "   Pages with valid content: 69\n",
      "   Average word count: 29586.4\n",
      "   Average readability score: 24.9\n",
      "\n",
      " Duplicate Detection Results:\n",
      "   Duplicate pairs found: 78\n",
      "   Thin content pages: 12 (14.8%)\n",
      "   Similarity threshold used: 0.8\n",
      "\n",
      " Model Performance:\n",
      "   Model type: Random Forest Classifier\n",
      "   Test accuracy: 0.960\n",
      "   Baseline accuracy: 0.120\n",
      "   Performance improvement: 0.840\n",
      "\n",
      " Quality Distribution:\n",
      "   Low quality: 45 pages (55.6%)\n",
      "   Medium quality: 31 pages (38.3%)\n",
      "   High quality: 5 pages (6.2%)\n",
      "\n",
      " Key Features Used:\n",
      "   3. flesch_reading_ease: 0.635\n",
      "   2. sentence_count: 0.158\n",
      "   4. avg_word_length: 0.129\n",
      "   1. word_count: 0.077\n",
      "\n",
      " All files successfully saved and ready for submission!\n",
      " Real-time analysis function 'analyze_url()' is ready to use!\n"
     ]
    }
   ],
   "source": [
    "# Final data export summary\n",
    "print(\"=== FINAL DATA EXPORT SUMMARY ===\")\n",
    "print(f\"Data files created:\")\n",
    "print(f\"    ../data/extracted_content.csv - Parsed HTML content\")\n",
    "print(f\"    ../data/features.csv - Extracted features with embeddings\")\n",
    "print(f\"    ../data/duplicates.csv - Duplicate content pairs\")\n",
    "print(f\"    ../models/quality_model.pkl - Trained classification model\")\n",
    "\n",
    "print(f\"\\n Processing Statistics:\")\n",
    "print(f\"   Total pages processed: {len(features_df)}\")\n",
    "print(f\"   Pages with valid content: {(features_df['word_count'] > 0).sum()}\")\n",
    "print(f\"   Average word count: {features_df['word_count'].mean():.1f}\")\n",
    "print(f\"   Average readability score: {features_df['flesch_reading_ease'].mean():.1f}\")\n",
    "\n",
    "print(f\"\\n Duplicate Detection Results:\")\n",
    "print(f\"   Duplicate pairs found: {len(duplicate_pairs)}\")\n",
    "print(f\"   Thin content pages: {thin_content_count} ({thin_content_count/len(features_df)*100:.1f}%)\")\n",
    "print(f\"   Similarity threshold used: {SIMILARITY_THRESHOLD}\")\n",
    "\n",
    "print(f\"\\n Model Performance:\")\n",
    "print(f\"   Model type: Random Forest Classifier\")\n",
    "print(f\"   Test accuracy: {accuracy:.3f}\")\n",
    "print(f\"   Baseline accuracy: {baseline_accuracy:.3f}\")\n",
    "print(f\"   Performance improvement: {(accuracy - baseline_accuracy):.3f}\")\n",
    "\n",
    "print(f\"\\n Quality Distribution:\")\n",
    "for label, count in label_counts.items():\n",
    "    percentage = count / len(features_df) * 100\n",
    "    print(f\"   {label} quality: {count} pages ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n Key Features Used:\")\n",
    "for idx, row in feature_importance.iterrows():\n",
    "    print(f\"   {idx+1}. {row['feature']}: {row['importance']:.3f}\")\n",
    "\n",
    "print(f\"\\n All files successfully saved and ready for submission!\")\n",
    "print(f\" Real-time analysis function 'analyze_url()' is ready to use!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
